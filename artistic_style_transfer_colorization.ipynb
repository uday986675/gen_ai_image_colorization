{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog, ttk, messagebox\n",
        "import numpy as np\n",
        "from PIL import Image, ImageTk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import cv2\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "class ArtisticColorizationSystem:\n",
        "    def __init__(self):\n",
        "        # Available artistic styles\n",
        "        self.styles = {\n",
        "            \"Van Gogh (Starry Night)\": \"vangogh\",\n",
        "            \"Monet (Water Lilies)\": \"monet\",\n",
        "            \"Picasso (Cubist)\": \"picasso\",\n",
        "            \"Hokusai (The Great Wave)\": \"hokusai\",\n",
        "            \"Rembrandt (Chiaroscuro)\": \"rembrandt\",\n",
        "            \"Modern Pop Art\": \"popart\",\n",
        "            \"Impressionist\": \"impressionist\",\n",
        "            \"No Style (Natural Color)\": \"natural\"\n",
        "        }\n",
        "\n",
        "        # Initialize models\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.colorization_model = None\n",
        "        self.style_transfer_model = None\n",
        "        self.vgg19 = None\n",
        "\n",
        "        # GUI components\n",
        "        self.root = None\n",
        "        self.input_image = None\n",
        "        self.output_image = None\n",
        "        self.style_var = None\n",
        "\n",
        "        self.setup_models()\n",
        "\n",
        "    def setup_models(self):\n",
        "        \"\"\"Initialize the colorization and style transfer models\"\"\"\n",
        "        print(\"Setting up models...\")\n",
        "\n",
        "        # Setup VGG19 for style extraction (simplified)\n",
        "        self.vgg19 = models.vgg19(pretrained=True).features.to(self.device).eval()\n",
        "\n",
        "        # For the demo, we'll use a simplified approach\n",
        "        # In production, you would load pretrained colorization and style transfer models\n",
        "        print(\"Models initialized (simulated for demo)\")"
      ],
      "metadata": {
        "id": "-wyOtnYE8SFk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CORE MODELS:"
      ],
      "metadata": {
        "id": "8n9WiPkR60e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorizationNet(nn.Module):\n",
        "    \"\"\"U-Net based architecture for colorization\"\"\"\n",
        "    def __init__(self, input_channels=1, output_channels=2):\n",
        "        super(ColorizationNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder2 = nn.Sequential(\n",
        "            nn.Conv2d(384, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        )\n",
        "\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            nn.Conv2d(192, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, output_channels, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(enc1)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(enc2)\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        dec2 = self.decoder2(torch.cat([bottleneck, enc2], dim=1))\n",
        "        dec1 = self.decoder1(torch.cat([dec2, enc1], dim=1))\n",
        "\n",
        "        return dec1"
      ],
      "metadata": {
        "id": "okkcSyU4yXzC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyleTransfer:\n",
        "    \"\"\"Apply artistic styles to colorized images\"\"\"\n",
        "    @staticmethod\n",
        "    def extract_features(image, model):\n",
        "        \"\"\"Extract features from VGG19 layers\"\"\"\n",
        "        features = []\n",
        "        x = image\n",
        "        for i, layer in enumerate(model):\n",
        "            x = layer(x)\n",
        "            if i in {1, 6, 11, 20, 29}:  # Selected layers for style/content\n",
        "                features.append(x)\n",
        "        return features\n",
        "\n",
        "    @staticmethod\n",
        "    def gram_matrix(tensor):\n",
        "        \"\"\"Compute Gram matrix for style representation\"\"\"\n",
        "        _, d, h, w = tensor.size()\n",
        "        tensor = tensor.view(d, h * w)\n",
        "        gram = torch.mm(tensor, tensor.t())\n",
        "        return gram\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_style(colorized_img, style_name):\n",
        "        \"\"\"Apply specific artistic style to image\"\"\"\n",
        "        # Convert to LAB and then to RGB for processing\n",
        "        if isinstance(colorized_img, np.ndarray):\n",
        "            colorized_img = torch.from_numpy(colorized_img).float().to('cpu')\n",
        "\n",
        "        # In production, this would use actual style transfer models\n",
        "        # For demo, we apply simulated style effects\n",
        "        img_np = colorized_img.numpy().transpose(1, 2, 0)\n",
        "\n",
        "        # Apply different filters based on selected style\n",
        "        if style_name == \"vangogh\":\n",
        "            # Simulate Van Gogh's brush strokes\n",
        "            return StyleTransfer.apply_vangogh_effect(img_np)\n",
        "        elif style_name == \"monet\":\n",
        "            # Simulate Monet's impressionism\n",
        "            return StyleTransfer.apply_monet_effect(img_np)\n",
        "        elif style_name == \"popart\":\n",
        "            # Simulate pop art effect\n",
        "            return StyleTransfer.apply_popart_effect(img_np)\n",
        "        elif style_name == \"natural\":\n",
        "            # No style, return original\n",
        "            return img_np\n",
        "        else:\n",
        "            # Default mild artistic effect\n",
        "            return StyleTransfer.apply_default_artistic(img_np)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_vangogh_effect(img):\n",
        "        \"\"\"Simulate Van Gogh's style\"\"\"\n",
        "        # This would be replaced with actual neural style transfer\n",
        "        # For demo, using OpenCV filters\n",
        "        result = cv2.stylization(img, sigma_s=60, sigma_r=0.6)\n",
        "        result = cv2.detailEnhance(result, sigma_s=10, sigma_r=0.15)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_monet_effect(img):\n",
        "        \"\"\"Simulate Monet's impressionist style\"\"\"\n",
        "        result = cv2.edgePreservingFilter(img, flags=1, sigma_s=60, sigma_r=0.4)\n",
        "        # Add warm impressionist tone\n",
        "        result = cv2.applyColorMap(result, cv2.COLORMAP_SUMMER)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_popart_effect(img):\n",
        "        \"\"\"Apply pop art style\"\"\"\n",
        "        # Posterization effect\n",
        "        result = cv2.medianBlur(img, 3)\n",
        "        Z = result.reshape((-1, 3))\n",
        "        Z = np.float32(Z)\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "        K = 8\n",
        "        _, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "        center = np.uint8(center)\n",
        "        result = center[label.flatten()].reshape((result.shape))\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_default_artistic(img):\n",
        "        \"\"\"Default artistic enhancement\"\"\"\n",
        "        result = cv2.detailEnhance(img, sigma_s=10, sigma_r=0.15)\n",
        "        return result"
      ],
      "metadata": {
        "id": "niM4_UH2yv51"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main application entry point\"\"\"\n",
        "    print(\"Starting Artistic Style Transfer in Colorization System...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Check for required packages\n",
        "    try:\n",
        "        import torch\n",
        "        import torchvision\n",
        "        import PIL\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "    except ImportError as e:\n",
        "        print(f\"Error: Missing required package - {e}\")\n",
        "        print(\"Please install required packages:\")\n",
        "        print(\"pip install torch torchvision pillow opencv-python numpy\")\n",
        "        return\n",
        "\n",
        "    # Create and run the system\n",
        "    # system = ArtisticColorizationSystem()\n",
        "    # gui = ArtisticColorizationGUI(system)\n",
        "    # gui.run()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "5vRGLE3O_qPF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GUI Interface\n"
      ],
      "metadata": {
        "id": "5Mqn2vFv6ptC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53d1395c"
      },
      "source": [
        "The `TclError` means that a graphical user interface (GUI) application is trying to run in a headless environment (like Colab) without a display server. To fix this, we will modify the `main` function to not initialize the `tkinter` GUI directly. If you need a graphical output, consider alternative visualization methods like displaying images directly in the notebook output using `matplotlib` or saving them to files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio torch torchvision Pillow opencv-python numpy\n"
      ],
      "metadata": {
        "id": "efwXIxlwi1qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def apply_style_effect(image, style_name):\n",
        "    \"\"\"Apply artistic style effects using OpenCV\"\"\"\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    if style_name == \"Van Gogh\":\n",
        "        # Stylization effect\n",
        "        result = cv2.stylization(img_array, sigma_s=60, sigma_r=0.6)\n",
        "    elif style_name == \"Monet\":\n",
        "        # Impressionist effect\n",
        "        result = cv2.edgePreservingFilter(img_array, flags=1, sigma_s=60, sigma_r=0.4)\n",
        "    elif style_name == \"Picasso\":\n",
        "        # Cubist-like effect\n",
        "        result = cv2.detailEnhance(img_array, sigma_s=10, sigma_r=0.15)\n",
        "    elif style_name == \"Hokusai\":\n",
        "        # Woodblock print effect\n",
        "        result = cv2.applyColorMap(img_array, cv2.COLORMAP_SUMMER)\n",
        "    elif style_name == \"Pop Art\":\n",
        "        # Posterization effect\n",
        "        Z = img_array.reshape((-1,3))\n",
        "        Z = np.float32(Z)\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "        K = 8\n",
        "        _, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "        center = np.uint8(center)\n",
        "        result = center[label.flatten()].reshape((img_array.shape))\n",
        "    else:  # Natural\n",
        "        result = img_array\n",
        "\n",
        "    return Image.fromarray(result)\n",
        "\n",
        "def colorize_and_style(input_image, style_choice):\n",
        "    \"\"\"Main processing function\"\"\"\n",
        "    # Convert to grayscale first (simulating colorization input)\n",
        "    if input_image.mode != 'L':\n",
        "        grayscale = input_image.convert('L')\n",
        "        # Convert back to RGB for demo (simulating colorization)\n",
        "        colorized = Image.merge('RGB', [grayscale, grayscale, grayscale])\n",
        "    else:\n",
        "        colorized = Image.merge('RGB', [input_image, input_image, input_image])\n",
        "\n",
        "    # Apply selected style\n",
        "    styled_image = apply_style_effect(colorized, style_choice)\n",
        "\n",
        "    return styled_image\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=colorize_and_style,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\"Van Gogh\", \"Monet\", \"Picasso\", \"Hokusai\", \"Pop Art\", \"Natural\"],\n",
        "            value=\"Natural\",\n",
        "            label=\"Select Artistic Style\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Image(type=\"pil\", label=\"Styled Output\"),\n",
        "    title=\"ðŸŽ¨ Artistic Style Transfer in Colorization\",\n",
        "    description=\"Upload an image and select an artistic style to apply. The system will colorize (simulated) and apply the selected style.\",\n",
        "    examples=[\n",
        "        [\"https://images.unsplash.com/photo-1506744038136-46273834b3fb\", \"Van Gogh\"],\n",
        "        [\"https://images.unsplash.com/photo-1519681393784-d120267933ba\", \"Monet\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Launch in Colab\n",
        "iface.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "91Gt4eUC-OZc",
        "outputId": "f8abb816-a06a-464e-c5b8-8b392ca56435"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://29abe7b4071f022e9e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://29abe7b4071f022e9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://29abe7b4071f022e9e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}